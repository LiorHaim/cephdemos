# How I've built my first K8S Operator using Ansible

Today I will share with you guys the infromation on how to implement a "real world" operator using Ansible, Let's first unserstand what operators are. Operators are software extention to Kubernetes that allow us to create custom resources to manage apllications and their resources. With operators, we could create an abstract, high-level object which will refer to the kubernetes objectives and create those resources in an automated way, The operator will act as a listener for this object's creation. In addition to this object (AKA custom resource, CR) we will also create a CRD (AKA custom resource definition) that will be the template for the CR. For example, in order to create an ELK stack on top of Kubernetes, we will have to create manifests for the pods, services to those pods, PVs, PVCs, routs etc. To ease the process of deploying such an ELK stack on top of our K8S cluster, we can create a CR that will be called for example `elk_stack` and will have it's own attributes (attributes will be stored in the CRD), for example num_elastic_nodes, num_kibana_nodes, num_logstash_instances etc. When creating this CR, the operator will automatically react and create the wanted resources according to the end-user's specification. Eventually, the end-user will have a running, functional ELK stack ready for use. After having this short introduction, let's talk about what we have in store for this demo. 
In this demo we will use the `dockercoins` project, which uses five simple microservices written in diffrernt programming languages (Ruby, Python, Node), We will build a `dockercoins` operator that will react to every CR that we create. The CR is actually a cluster that gathers all those five microservices into one object. When creating the CR the operator will create the deployments, services, routs, etc behind the scenes. Eventually we will end up with a `dockercoins` cluster that was created using our CR and it's attributes. If you think of it, in the real world we can take any application that we have and implemet some logic to it using Operators. This logic will perform day1 operations (such as initial deploymet) and day2 operations (such as migration, scaling, etc) and all we'll have to do is to use the right manifest. 

Let's talk a little bit about the `dockercoins` microservices architecture to understand a little more about the dynamics: 
* rng service - written web service generating random bytes
* hasher service - web service computing hash of POSTed data
* worker service background process using rng and hasher
* webui service - web interface to watch progress
* redis service - stores progress information 

The worker service takes the generated bytes made up by the rng service, hashes them using the hasher service and writes the progress information to redis. The webui service then extracts the information from redis and presents a nice graph of hashes/minute to the screen. 

Let's start with the demo!

## Prerequisites
* A running Openshift cluster (mine is 4.3.8) 
* An executable operator-sdk binary (v0.16.0)

Let's create a new project in Openshift in which the dockercoins cluster will by deployed:
```bash
oc new-project dockercoins
```

Now we'll generate the dockercoins-operator manifests using the operator-sdk command and then change the directory context: 
```bash
operator-sdk new dockercoins --type=ansible --api-version=dockercoins.example.com/v1alpha1 --kind=Dockercoins && cd dockercoins
```

This command will create a folder that contains all the needed files for us to build the operator. Next, we'll pull the dockercoins ansible role from Ansible Galaxy: 
```bash 
ansible-galaxy install shonpaz123.dockercoins -p ./roles
rm -rf roles/dockercoins
mv roles/shonpaz123.dockercoins roles/dockercoins

```

The operator sdk will create a role called shonpaz123.dockercoins by default, so in order to use the same role specified in the watchers.yaml file we will delete the role that was created by the operator sdk and rename the installed role to `dockercoins`. 

## About dockercoins Ansible Role

In this demo we will use ansible roles to build the operator's logic. Every time the end-user creates a CR, the operator will take a look at the watchers.yaml file (to understand which role should be executed) and will trigger an ansible-runner that calls the needed playbooks. In those playbooks we can use all ansible objectives such as Jinja templates, default variables, tasks etc. In our case, the main.yaml playbook calls other playbooks to create the Kubernetes resources needed. Those playbooks use a Jinja template to render variables and create the needed resources. Let's take a quick look of the implementation: 

```bash 
cat roles/dockercoins/tasks/main.yml
---
- name: start redis deployment to "{{ state }}"
  k8s:
   state: "{{ state }}"
   definition: "{{ lookup('template', 'redis-deployment.yaml.j2') | from_yaml }}"
   namespace: "{{ meta.namespace }}"
```

This example shows that the main.yaml playbook that is called by the ansible-runner, uses the K8S ansible module to interact with our Openshift cluster. this task looks for a Jinja template located in the templates dir, This template looks as the following: 

```bash 
cat roles/dockercoins/templates/redis-deployment.yaml.j2                                                                            
kind: Deployment
apiVersion: apps/v1
metadata:
  name: redis
spec:
  replicas: {{ redis_replicas|default(size) }}
  selector:
    matchLabels:    
      app: redis
  template:    
    metadata:
      labels:  
        app: redis
    spec:
      containers:
        - name: redis
          image: redis
          ports:
            - containerPort: 6379
              protocol: TCP
```

As you see, this looks as a regular Kubernetes deployment that creates a redis deployment, this is exactly what will be created after we will reate the CR.
We could also specify ansible extra-vars (such as redis_replicas) that will be transfered through the CR spec section, and the playbook will render those vars into the playbook. We'll see how this happens later on. To sum things up, the basic architecture is: 

Operator --> watchers.yaml --> ansible-runner --> ansible role --> ansible K8S module --> resource creation --> Acknowledge 

After we know a little more on how things work, let's move on with the demo. The next thing we want to do is to create the CRD that will be used as the CR template:

```bash 
oc create -f deploy/crds/dockercoins.example.com_dockercoins_crd.yaml
```

Now we can build our operator image: 
```bash 
sudo operator-sdk build shonpaz123/dockercoins-operator:v0.0.1  
                                                          
INFO[0000] Building OCI image shonpaz123/dockercoins-operator:v0.0.1 
Sending build context to Docker daemon  63.49kB
Step 1/5 : FROM quay.io/operator-framework/ansible-operator:v0.16.0
 ---> 19ba5006a265
Step 2/5 : COPY requirements.yml ${HOME}/requirements.yml
 ---> Using cache
 ---> 1374cf30e0a8
Step 3/5 : RUN ansible-galaxy collection install -r ${HOME}/requirements.yml  && chmod -R ug+rwx ${HOME}/.ansible
 ---> Using cache
 ---> b0b4385a4b17
Step 4/5 : COPY watches.yaml ${HOME}/watches.yaml
 ---> Using cache
 ---> 80f801af37eb
Step 5/5 : COPY roles/ ${HOME}/roles/
 ---> 79199b06bc4b
Successfully built 79199b06bc4b
Successfully tagged shonpaz123/dockercoins-operator:v0.0.1
INFO[0000] Operator build complete.        
```

We have used the operator-sdk command to build our operator container image including a tag, now we can push it to a container registry (in our case, Docker Hub). Notice that for disconnected container registries you will need the add some extra configuration (add pull secrets and link the to the right service account).              
Let's push the image: 

```bash 
sudo docker push shonpaz123/dockercoins-operator:v0.0.1
```

After the push was successful, we need to replace the operator image name in the operator deployment:

```bash
sed -i  "s|\"REPLACE_IMAGE\"|shonpaz123/dockercoins-operator:v0.0.1|g" deploy/operator.yaml
```
This command commits the right image name into the operator's deployment yaml. 
Let's continue with the creation of the RBAC roles, service account, and security constraints:

```bash 
oc create -f deploy/service_account.yaml
oc create -f deploy/role.yaml
oc create -f deploy/role_binding.yaml
oc adm policy add-role-to-user admin system:serviceaccount:dockercoins:dockercoins
oc adm policy add-scc-to-user anyuid -z default
```

These manifest are crucial, we need them to allow the user that was created by the operator-sdk to interact with our Openshift cluster. 
Now we can deploy our operator: 

```bash 
oc create -f deploy/operator.yaml
```
Now let's take a look on the pods: 

```bash 
oc get pods                                                                                                                          
NAME                           READY   STATUS        RESTARTS   AGE
dockercoins-84446678bc-6zpkq   1/1     Running       0          88m
```

So we see that we our operator is running and waiting for a CR creation, before we create it let's take a look at the CR manifest: 

```bash 
cat deploy/crds/dockercoins.example.com_v1alpha1_dockercoins_cr.yaml                                                                  
apiVersion: dockercoins.example.com/v1alpha1
kind: Dockercoins
metadata:
  name: example-dockercoins
spec:
  # Add fields here
  size: 3
```

So our default CR look like that, let's change it a bit to understand how we could use ansible extra-vars to create a greater flexabillity. Previous in this demo we saw that in the Jinja template we have a variable definition `{{ redis_replicas|default(size) }}` This definition says that in case we have redis_replicas variable defined we can use it, in case it's not, we will fetch it from our default variables in the `defaults` directory. There is no `redis_replicas` variable neither in vars nor in defaults directories. That is why we will render those vars to ansible using the CR's spec section. The CR should look like this: 

```bash 
apiVersion: dockercoins.example.com/v1alpha1
kind: Dockercoins
metadata:
  name: dockercoins-cluster
spec:
  # Add fields here
  redis_replicas: 2
  worker_replicas: 2 
  webui_replicas: 4
```

As you see, we have used our own attributes that create the `dockercoins` cluster, and we can actually control which variables can be changed in our ansible role. This CR will create a cluster where we use the default size (3) to the hasher and the rng services, but the rest of the services will get their replica size using the following CR. Now we can create the CR and see if those vars were successfuly rendered to the ansible-runner:

```bash
oc create -f deploy/crds/dockercoins.example.com_v1alpha1_dockercoins_cr.yaml
```

Let's take a look at the pods: 

```bash 
oc get pods                                                                                                                        
NAME                           READY   STATUS    RESTARTS   AGE
dockercoins-84446678bc-6zpkq   1/1     Running   0          105m
hasher-7fb454b674-plbz9        1/1     Running   0          17s
hasher-7fb454b674-qj2xf        1/1     Running   0          17s
hasher-7fb454b674-snlwp        1/1     Running   0          17s
redis-8687bfc768-xcddq         1/1     Running   0          20s
redis-8687bfc768-zgcvg         1/1     Running   0          20s
rng-58c7d9748-tcrfx            1/1     Running   0          14s
rng-58c7d9748-w78sl            1/1     Running   0          14s
rng-58c7d9748-xk7kl            1/1     Running   0          14s
webui-5c7654c5bc-cvtq4         1/1     Running   0          9s
webui-5c7654c5bc-f2k5w         1/1     Running   0          9s
webui-5c7654c5bc-ppz52         1/1     Running   0          9s
webui-5c7654c5bc-tmb8j         1/1     Running   0          9s
worker-746686b79d-9gq8t        1/1     Running   0          10s
worker-746686b79d-bnsm6        1/1     Running   0          10s
```

```bash 
oc get pods | grep -v "NAME" | grep -v "dockercoins" | awk '{print $1}' | awk -F "-" '{print $1}' | uniq -c                 
      3 hasher
      2 redis
      3 rng
      4 webui
      2 worker
```
As you see, for the specified replicas, we had the specified number, but for those who were not specified, ansible used the default size. Let's scale down the webui service and apply the configuration:

```bash 
apiVersion: dockercoins.example.com/v1alpha1
kind: Dockercoins
metadata:
  name: dockercoins-cluster
spec:
  # Add fields here
  redis_replicas: 2
  worker_replicas: 2 
  webui_replicas: 2
```

```bash 
oc apply -f deploy/crds/dockercoins.example.com_v1alpha1_dockercoins_cr.yaml
```

We see we have 2 replicas in Terminating state, which means the service has scaled down: 

```bash 
oc get pods                                                                                                                        
NAME                           READY   STATUS        RESTARTS   AGE
dockercoins-84446678bc-6zpkq   1/1     Running       0          111m
hasher-7fb454b674-plbz9        1/1     Running       0          6m28s
hasher-7fb454b674-qj2xf        1/1     Running       0          6m28s
hasher-7fb454b674-snlwp        1/1     Running       0          6m28s
redis-8687bfc768-xcddq         1/1     Running       0          6m31s
redis-8687bfc768-zgcvg         1/1     Running       0          6m31s
rng-58c7d9748-tcrfx            1/1     Running       0          6m25s
rng-58c7d9748-w78sl            1/1     Running       0          6m25s
rng-58c7d9748-xk7kl            1/1     Running       0          6m25s
webui-5c7654c5bc-cvtq4         1/1     Terminating   0          6m20s
webui-5c7654c5bc-f2k5w         1/1     Running       0          6m20s
webui-5c7654c5bc-ppz52         1/1     Terminating   0          6m20s
webui-5c7654c5bc-tmb8j         1/1     Running       0          6m20s
worker-746686b79d-9gq8t        1/1     Running       0          6m21s
worker-746686b79d-bnsm6        1/1     Running       0          6m21s
```

Let's verify that: 

```bash 
oc get pods | grep -v "NAME" | grep -v "dockercoins" | awk '{print $1}' | awk -F "-" '{print $1}' | uniq -c                        
      3 hasher
      2 redis
      3 rng
      2 webui
      2 worker
```

You can use the `oc get svc` to ensure all services were created as expected, Let's take a look at the route created for the webui and see if we can see the webui graph: 

```bash 
oc get route 

NAME    HOST/PORT                            PATH   SERVICES   PORT   TERMINATION   WILDCARD
webui   webui-dockercoins.apps-crc.testing          webui      80                   None
```
Now let's access to `webui-dockercoins.apps-crc.testing`and see if we get the graph: 

================ PICTURE

We have Succeeded!


## Conclusion 

So we saw how we can create an operator that will be listening to our CR creations. This development method becomes very popular when dealing with K8S/Openshift, allowing the developers to use K8S resources with well knows achronyms. Hope you have enjoyes this demo, Thanks for reading :)

